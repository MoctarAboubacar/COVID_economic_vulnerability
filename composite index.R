rm(list = ls())

require(xlsx)
require(readxl)
require(tidyverse)
require(psych)
require(sf)
require(rmapshaper)
require(ggspatial)
require(factoextra)
require(PerformanceAnalytics)


# column name function
colname.fun <- function(df, cols){
  vec <- vector()
  for (i in cols){
    vec[i] <- which(colnames(df) == i)
  }
  return(vec)
}


# load data
df <- read_excel("C:/Users/moctar.aboubacar/Desktop/1_test_data.xlsx",
                 na = "#N/A")


# take out all the national parks and reservations etc.
# impute the mean by district
df$S1.3.most_affected[df$S1.3.most_affected == 0] <- NA
df$S3.2palika_income[df$S3.2palika_income == 0] <- NA

df <- df %>% 
  filter(LU_Type != "National Park",
         LU_Type != "Hunting Reserve",
         LU_Type != "Wildlife Reserve",
         S1.1.Avg_P0WB > 0) %>% 
  group_by(DISTRICT) %>% 
  mutate(S1.3.most_affected = ifelse(is.na(S1.3.most_affected), mean(S1.3.most_affected, na.rm = TRUE), S1.3.most_affected),
         S3.2palika_income = ifelse(is.na(S3.2palika_income), mean(S3.2palika_income, na.rm = TRUE), S3.2palika_income)) %>% 
  group_by(STATE) %>% 
  mutate(S3.2palika_income = ifelse(is.na(S3.2palika_income), mean(S3.2palika_income, na.rm = TRUE), S3.2palika_income)) # All Palikas in Dankhuta District are NAs for income, so the mean value of the Province (STATE) is used


# identify and deal with NAs
sapply(df, function(x) sum(x == 0)/nrow(df)) # % 0s by variable
sapply(df, function(x) sum(is.na(x))/nrow(df)) # % NAs by variable
x <- sapply(df, function(x) sum(is.na(x)))
table(x)


# examine the distributions of all variables of interest, ID variables for further processing
glimpse(df)

## univariate
df.eda <- df[,c(9:26)]
names(df.eda)

ggplot(gather(df.eda), aes(value))+
  geom_histogram(bins = 10)+
  facet_wrap(~key, scales = 'free')


######Variable processing
df <- df %>% 
  mutate(S2.1.migrant_india = case_when(S2.1.Migrants_india_pcn < 0.025 ~ 1,
                                        S2.1.Migrants_india_pcn >= 0.025 & S2.1.Migrants_india_pcn < 0.05 ~ 2,
                                        S2.1.Migrants_india_pcn >= 0.05 & S2.1.Migrants_india_pcn < 0.1 ~ 3,
                                        S2.1.Migrants_india_pcn >= 0.1 ~ 4),
         S2.1.migrant_other = case_when(S2.1.Migrants_other_pcn < 0.05 ~ 1,
                                        S2.1.Migrants_other_pcn >= 0.05 & S2.1.Migrants_other_pcn < 0.1 ~ 2,
                                        S2.1.Migrants_other_pcn >= 0.1 & S2.1.Migrants_other_pcn < 0.16 ~ 3,
                                        S2.1.Migrants_other_pcn >= 0.16 & S2.1.Migrants_other_pcn < 0.25 ~ 4,
                                        S2.1.Migrants_other_pcn >= 0.25 ~ 5),
         S1.3.most_affected = (S1.3.most_affected * 5) / Population2020,
         S3.2palika_income = S3.2palika_income / Population2020,
         S3.1.Remoteness = abs(max(S3.1.Remoteness) - S3.1.Remoteness)) # reverse the sign of the Remoteness index so that higher values represent lower remoteness


# multivariate analysis
# 1 is the Sensitivity sub-index grouping appropriate?
# # (Despite a high Cronbach's alpha), with multiple variables, we want to ensure that our aggregation method is not, by the multiplicity of variables, de-facto giving less weight to important dimensions. We find that there are clearly 3 groups giving different sources of information and go with that group breakdown, because it also makes interpretative sense.
# 
# test_sensitivity <- df[colname.fun(df,c("S1.1.Avg_P0", "S1.1.Avg_K0", "S1.1.Avg_S2", "S1.1.Avg_U2","S1.1.Avg_P0WB","S1.3.dependency_ratio", "S1.2.Avg_W2", "S1.2.Avg_D_1", "S1.3.most_affected"))]
# 
# chart.Correlation(test_sensitivity)
# 
# test_sensitivity_scale <- as.data.frame(scale(test_sensitivity))
# 
# alpha(test_sensitivity, check.keys = T) 
# 
# test_sensitivity_pca <- prcomp(test_sensitivity_scale)
# test_sensitivity_pca
# fviz_pca_var(test_sensitivity_pca,
#              col.var = "contrib",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE)
# 
# # 2 is Exposure covering the same information twice?
# # Correlation coefficient between vulnerable caste and exposed work is 0.46. This is most likely because of overlap in the counting--people who are vulnerable are more likely to have exposed livelihoods. But the correlation is not particularly high. Alpha for the entire sub-index is low.
# # Migration from INdia + from other sources are not correlated, and very far from each other in the PCA analysis.
# # Solutions (a) Keep the structure as-is, grouping migration (b) ungroup migration. The migration variables are not correlated and so not allowing regional differences to show up. From an interpretive standpoint option (a) is better. From a statistical standpoint I think (b) is better. Try both, see acceptability of results.
# # After comparing the 2 solutions, we see very little change, and the change does not really result in an overall re-prioritization of high-migrant dependent areas...not really. So we conclude that option (a) is a good one and stick with it.
# 
# test_exposure <- df[colname.fun(df,c("S2.1.migrant_india", "S2.1.migrant_other", "S2.2.exposed_work", "S2.3.pcnvulcaste"))]
# 
# chart.Correlation(test_exposure)
# 
# test_exposure_scale <- as.data.frame(scale(test_exposure))
# 
# alpha(test_exposure, check.keys = T) 
# 
# test_exposure_pca <- prcomp(test_exposure_scale)
# fviz_pca_var(test_exposure_pca,
#              col.var = "contrib",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE)
# 
# ggplot(df, aes(S2.2.exposed_work, S2.3.pcnvulcaste, color = STATE))+
#   geom_point()+
#   geom_smooth(method = 'lm', se = F)
# summary(lm(S2.2.exposed_work ~ S2.3.pcnvulcaste, data = df_5))
# 
# 
# # 3 is the Adaptive Capacity measure grouped properly? (should it be grouped by HDI and Palika $ or no?)
# # weak correlations across all 3 variables (including with the log of per-palika)
# # Correlations are weak and PCA shows factor loadings quite different across principal components. The conclusion is that statistically, it makes sense to keep these variables apart.
# test_ac <- df[colname.fun(df,c("S3.2HDI","S3.1.Remoteness", "S3.2palika_income"))]
# # test_ac$S3.2palika_income <- log(test_ac$S3.2palika_income)
# 
# chart.Correlation(test_ac)
# 
# test_ac__scale <- as.data.frame(scale(test_ac))
# 
# alpha(test_ac, check.keys = T) 
# 
# test_ac_pca <- prcomp(test_ac__scale)
# fviz_pca_var(test_ac_pca,
#              col.var = "contrib",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE)


# percentile ranking of variables

df_2 <- df[colname.fun(df, c("GCODE", "HLCIT_CODE", "STATE", "DISTRICT", "Population2020", "S1.1.Avg_P0", "S1.1.Avg_K0", "S1.1.Avg_S2", "S1.1.Avg_U2","S1.1.Avg_P0WB","S1.3.dependency_ratio", "S1.2.Avg_W2", "S1.2.Avg_D_1",  "S2.3.pcnvulcaste",  "S2.1.migrant_india", "S2.1.migrant_other", "S1.3.most_affected","S3.2palika_income", "S3.2HDI", "S2.2.exposed_work", "S3.1.Remoteness"))]

df_3 <- map_df(df_2[6:21], cume_dist)

df_3$STATE <- df_2$STATE
df_3$DISTRICT <- df_2$DISTRICT
df_3$GCODE <- df_2$GCODE
df_3$HLCIT_CODE <- df_2$HLCIT_CODE
df_3$Population2020 <- df_2$Population2020


df_5 <- df_3 %>% 
  mutate(migrants = cume_dist(S2.1.migrant_india + S2.1.migrant_other),
         Exposure = cume_dist(migrants + S2.2.exposed_work + S2.3.pcnvulcaste),
         Pov_foodsec = cume_dist(S1.1.Avg_P0 + S1.1.Avg_P0WB + S1.1.Avg_S2 + S1.1.Avg_K0 + S1.1.Avg_U2 + S1.3.dependency_ratio),
         hygiene_nut = cume_dist(S1.2.Avg_W2 + S1.2.Avg_D_1),
         Sensitivity = cume_dist(Pov_foodsec + hygiene_nut + S1.3.most_affected),
         AdaptiveCapacity = cume_dist(S3.2palika_income + S3.2HDI + S3.1.Remoteness),
         Index_add = cume_dist(Exposure + Sensitivity - AdaptiveCapacity),
         Index_geo = cume_dist((Exposure * 100) * (Sensitivity * 100) / (AdaptiveCapacity * 100)),
         Index_add_quint = ntile(Index_add, 5),
         Index_geo_quint = ntile(Index_geo, 5),
         Exposure_quint = ntile(Exposure, 5),
         Sensitivity_quint = ntile(Sensitivity, 5),
         AdaptiveCapacity_quint = ntile(AdaptiveCapacity, 5))


df_index <- df_5[,colname.fun(df_5, c("GCODE","HLCIT_CODE", "STATE", "DISTRICT", "Sensitivity", "AdaptiveCapacity", "Index_add", "Index_add_quint", "Index_geo", "Index_geo_quint", "Exposure", "Exposure_quint", "Sensitivity", "Sensitivity_quint", "AdaptiveCapacity", "AdaptiveCapacity_quint", "Population2020"))]

df_index$Geo_Code <- df_index$GCODE
# map
# ## import shape file and load index data into it
# shp <- st_read("C:/Users/moctar.aboubacar/Desktop/Vul Index/Nepal vulnerability shapefile/combined_data_sae_popn_building_vul_caste.shp")
# 
# shp <- merge(shp, df_index[c("HLCIT_CODE", "Geo_Code", "Population2020", "Index_add", "Index_add_quint", "Index_geo", "Index_geo_quint", "Exposure", "Exposure_quint", "Sensitivity", "Sensitivity_quint","AdaptiveCapacity", "AdaptiveCapacity_quint")], all.x = TRUE)
# new shape file
shp <- st_read("C:/Users/moctar.aboubacar/Desktop/Nepal_Palikawise_Boundary_WGS/nepal_new_str_wgs_84.shp")

shp <- merge(shp, df_index[c("Geo_Code", "Population2020", "Index_add", "Index_add_quint", "Index_geo", "Index_geo_quint", "Exposure", "Exposure_quint", "Sensitivity", "Sensitivity_quint","AdaptiveCapacity", "AdaptiveCapacity_quint")], all.x = TRUE)



##### addressing missing data issue- 4 palikas in Sarlahi...the issue happens when merging based on the HLCIT code I'm pretty sure... should I be using the GCode?
df_missing <- shp %>% 
  filter(is.na(Index_geo),
         LU_Type != "National Park",
         LU_Type != "Hunting Reserve",
         LU_Type != "Wildlife Reserve",
         TYPE_EN != "Designated Area")
df_missing <- df_missing[,c(1:9)]
####


# create layers for District and Province
district <- shp %>% 
  group_by(DISTRICT) %>% 
  summarise(mean(Sensitivity)) %>% 
  ms_simplify()

province <- shp %>% 
  group_by(STATE_CODE) %>% 
  summarise(mean(Sensitivity)) %>% 
  ms_simplify()


# map it out (red, blue, purple, green)
shp$Index_geo_quint[is.na(shp$Index_geo_quint)] <- 6
shp$Exposure_quint[is.na(shp$Exposure_quint)] <- 6
shp$Sensitivity_quint[is.na(shp$Sensitivity_quint)] <- 6
shp$AdaptiveCapacity_quint[is.na(shp$AdaptiveCapacity_quint)] <- 6



plot_index <- ggplot(shp)+
  geom_sf(aes(fill = factor(Index_geo_quint), size = NA))+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#fee8c8","#fdd49e", "#fdbb84", "#ef6548", "#d7301f", "grey70"),
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "COVID Economic Vulnerability Index",
       fill = "Covid Vulnerability Index")

plot_exposure <- ggplot(shp)+
  geom_sf(aes(fill = factor(Exposure_quint), size = NA))+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#feebe2","#fbb4b9", "#f768a1", "#c51b8a", "#7a0177", "grey70"),
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Exposure Sub-Index",
       fill = "Exposure")

plot_sensitivity <- ggplot(shp)+
  geom_sf(aes(fill = factor(Sensitivity_quint), size = NA))+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#f0f9e8","#bae4bc", "#7bccc4", "#43a2ca", "#0868ac", "grey70"),
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Sensitivity Sub-Index",
       fill = "Sensitivity")

plot_adaptcapacity <- ggplot(shp)+
  geom_sf(aes(fill = factor(AdaptiveCapacity_quint), size = NA))+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#f7f7f7","#cccccc", "#969696", "#636363", "#252525", "#74c476"),
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Adaptive Capacity Sub-Index",
       fill = "Adaptive Capacity")



# by-Province results
df_dis_province <- shp %>%
  group_by(STATE_CODE) %>% 
  mutate(index_p = cume_dist(Index_geo),
         exposure_p = cume_dist(Exposure),
         sensitivity_p = cume_dist(Sensitivity),
         AdaptiveCapacity_p = cume_dist(AdaptiveCapacity),
         index_quint_p = ntile(index_p, 5),
         Exposure_quint_p = ntile(exposure_p, 5),
         Sensitivity_quint_p = ntile(sensitivity_p, 5),
         AdaptiveCapacity_quint_p = ntile(AdaptiveCapacity_p, 5)) %>% 
  ungroup()

df_dis_province$index_quint_p[is.na(df_dis_province$index_quint_p)] <- 6

plot_provwise <- ggplot(df_dis_province)+
  geom_sf(aes(fill = factor(index_quint_p), size = NA))+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#fee8c8","#fdd49e", "#fdbb84", "#ef6548", "#d7301f", "grey70"),
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Province-wise Vulnerability Index",
       fill = "Covid Vulnerability Index")




# District-grouped results mapping
df_dist <- shp %>%
  st_drop_geometry() %>% 
  filter(!is.na(Index_geo)) %>% 
  mutate(dist_ind = Index_geo * Population2020,
         dist_exposure = Exposure * Population2020,
         dist_sensitivity = Sensitivity * Population2020,
         dist_adaptivecapacity = AdaptiveCapacity * Population2020) %>% 
  group_by(DISTRICT) %>% 
  summarize(dist_ind = sum(dist_ind) / sum(Population2020),
            dist_exposure = sum(dist_exposure) / sum(Population2020),
            dist_sensitivity = sum(dist_sensitivity) / sum(Population2020),
            dist_adaptivecapacity = sum(dist_adaptivecapacity) / sum(Population2020)) %>% 
  mutate(dist_ind_quint = ntile(dist_ind, 5),
         dist_exposure = ntile(dist_exposure, 5),
         dist_sensitivity = ntile(dist_sensitivity, 5),
         dist_adaptivecapacity = ntile(dist_adaptivecapacity, 5))

glimpse(df_dist)


shp_dist <- merge(shp, df_dist[c("DISTRICT", "dist_ind", "dist_ind_quint", "dist_exposure", "dist_sensitivity", "dist_adaptivecapacity")], all.x = TRUE)

plot_index_dist <- ggplot(shp_dist)+
  geom_sf(aes(fill = factor(dist_ind_quint), size = NA))+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#fee8c8","#fdd49e", "#fdbb84", "#ef6548", "#d7301f", "grey70"),
                    
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Geometric Vulnerability Index",
       fill = "Covid Vulnerability Index")

plot_exposure_dist <- ggplot(shp_dist)+
  geom_sf(aes(fill = factor(dist_exposure), size = NA))+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#feebe2","#fbb4b9", "#f768a1", "#c51b8a", "#7a0177", "grey70"),
                    
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Exposure Sub-Index",
       fill = "Exposure")

plot_sensitivity_dist <- ggplot(shp_dist)+
  geom_sf(aes(fill = factor(dist_sensitivity), size = NA))+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#f0f9e8","#bae4bc", "#7bccc4", "#43a2ca", "#0868ac", "grey70"),
                    
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Sensitivity Sub-Index",
       fill = "Sensitivity")

plot_adaptivecapacity_dist <- ggplot(shp_dist)+
  geom_sf(aes(fill = factor(dist_adaptivecapacity), size = NA))+
  geom_sf(data = province, aes(fill = NA), lwd = 1.1)+
  geom_sf(data = district, aes(fill = NA), lwd = 0.7)+
  annotation_scale(location = "bl", width_hint = 0.4)+
  theme_void()+
  scale_fill_manual(values = c("#f7f7f7","#cccccc", "#969696", "#636363", "#252525", "#74c476"),
                    
                    labels = c("Very Low", "Low", "Moderate", "High", "Very High", "N/A"))+
  labs(title = "Adaptive Capacity Sub-Index",
       fill = "Adaptive Capacity")



## SENSITIVITY ANALYSIS: do ti differently and see how it works out

# additive vs. geometric aggregation of the 3 indices

# aggregation with weights (derived through...a method. Do one, make it really fast.) PCA/FA or other etc.

#  Dropping or otherwise playing with the exposure element


ggplot(df_index, aes(x = Sensitivity_quint, y = AdaptiveCapacity))+
  geom_col()
